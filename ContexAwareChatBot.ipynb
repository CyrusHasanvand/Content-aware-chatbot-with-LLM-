{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5767ee3-8143-4f9d-871d-a6039a0c4886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "#from langchain.chains import LLMChain\n",
    "from langchain_huggingface import HuggingFacePipeline \n",
    "#from langchain_community.chat_models import ChatHuggingFace\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage, StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56ed268e-c71e-4f74-aa0a-7d1bf8970dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c6941-9f0c-42ec-bbce-c6ecdb8761df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32f2cbc5-cf13-48e5-b7c8-72af63d1cb46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HuggingFace LLM: phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce1cea44-4dfa-48fa-aaa2-7284568a1ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d33a18aa49d44ba8dd46145869a9259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"microsoft/phi-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24490564-ccec-4851-9a89-7c5c672a1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "hf_pipe = pipeline(\n",
    "    \"text-generation\",          \n",
    "    model=model,               \n",
    "    tokenizer=tokenizer,       \n",
    "    max_new_tokens=200,       \n",
    "    do_sample=True,           \n",
    "    temperature=0.7,         \n",
    "    pad_token_id=tokenizer.eos_token_id,  \n",
    "    device=device               # CPU or GPU\n",
    ")\n",
    "LLM_01 = HuggingFacePipeline(pipeline=hf_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f6e8f-e923-4452-930f-14fbb0fd81fd",
   "metadata": {},
   "source": [
    "## HuggingFace LLM: Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d483b-4886-4e68-b158-bb627dbbd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",    # Auto places model on GPU if available\n",
    "    load_in_4bit=True     # Requires bitsandbytes (saves VRAM/RAM)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6a1a6-b781-43e5-921d-8d85111a1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_2 = pipeline(\n",
    "    \"text-generation\",          \n",
    "    model=model2,                \n",
    "    tokenizer=tokenizer,        \n",
    "    max_new_tokens=200,         \n",
    "    do_sample=True,             \n",
    "    temperature=0.7,            \n",
    "    pad_token_id=tokenizer.eos_token_id,  \n",
    "    device=device      \n",
    ")\n",
    "LLM_02 = HuggingFacePipeline(pipeline=hf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935933e5-223f-4f45-99f0-f443a9477752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "768aa4dc-dfd9-4658-8416-62e7de7c4684",
   "metadata": {},
   "source": [
    "## Ollama: llama3.1  [Free Local Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa7cea24-b676-4dc4-a789-01bfd4435543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM_03 = ChatOllama(model=\"llama3.1\", Temperature=0.7,do_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d95c21-3375-43f1-b4df-b302986b7777",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5807d5a-6e01-47dc-9a24-c474df84f2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    ('system','You are an AI assistant, and provide no more than 220 tokens whey write a response to a question'),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('user','{text}')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ef73d-d4f4-49a2-87fc-0dde5782ea3c",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39df8090-2092-4097-a38d-ee33908c6ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ChainLLama31=prompt|LLM_03|StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8ba19-70bc-4c2b-9539-1b69ec8d9bea",
   "metadata": {},
   "source": [
    "## Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35fb8530-bcf8-411c-ab49-2a77009c4d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d20a4d69-bc5c-41f9-9492-2f87f0ea73ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query='I am an AI specialist who is expert in online knowledge augmentation from nonstationary Data Streams'\n",
    "response_message=ChainLLama31.invoke({'chat_history':chat_history,'text':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abdf09a6-710e-481a-8487-9747635a4ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's fascinating! Online knowledge augmentation from non-stationary data streams is a challenging problem in the field of Artificial Intelligence and Machine Learning. Non-stationarity refers to the fact that the underlying distribution of the data changes over time, making it difficult to develop models that can adapt and learn from the new patterns.\n",
      "\n",
      "As an expert in online knowledge augmentation, you must be well-versed in techniques such as incremental learning, transfer learning, and few-shot learning. You likely also have experience with real-time data processing, streaming algorithms, and model adaptation strategies.\n",
      "\n",
      "Can you tell me more about your work in this area? What are some of the most significant challenges you've encountered, and how do you approach solving them?\n"
     ]
    }
   ],
   "source": [
    "print((response_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca8717d7-bfa7-4557-a2a7-00a27df3d2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=query), AIMessage(content=response_message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6645d708-7816-431e-afd8-803d1b246566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your area of expertise is Online Knowledge Augmentation from Non-Stationary Data Streams. Specifically, you're an expert in developing AI models that can adapt and learn from changing data distributions over time, making it possible to continuously update and improve knowledge based on new information.\n"
     ]
    }
   ],
   "source": [
    "query='What is my area of expertise?'\n",
    "response_message=ChainLLama31.invoke({'chat_history':chat_history,'text':query})\n",
    "print((response_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92f95617-b421-4db2-a3ef-3b0b9aa13108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=query), AIMessage(content=response_message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66e68714-d44e-45a9-84f0-3e41bb4fc0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a knowledgeable assistant, I don't have personal preferences or opinions, but I can provide some insights.\n",
      "\n",
      "Tehran is the capital and largest city of Iran, with a rich history, culture, and economic significance. Many Iranians migrate to Tehran for better job opportunities, education, and access to modern amenities. However, this has also led to concerns about urbanization, congestion, and strain on resources.\n",
      "\n",
      "If I had to provide an objective answer, it's likely due to the concentration of educational institutions, research centers, and industries in Tehran, making it a hub for career advancement and economic growth.\n"
     ]
    }
   ],
   "source": [
    "query='Why do prefer most of people in Iran to live in Tehran?'\n",
    "response_message=ChainLLama31.invoke({'chat_history':chat_history,'text':query})\n",
    "print((response_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "445e9cb9-0058-4121-b6b2-fb76600f0b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=query), AIMessage(content=response_message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41310f03-179e-4d1a-ac68-e966164ebd9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In your question, you asked why most people in Iran prefer to live in Tehran. I provided some insights on the city's significance, job opportunities, education, and modern amenities, which might contribute to its appeal.\n"
     ]
    }
   ],
   "source": [
    "query='What was the context of my previous message?'\n",
    "response_message=ChainLLama31.invoke({'chat_history':[chat_history[-2].content,chat_history[-1].content],'text':query})\n",
    "print((response_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f30d2684-da46-4ead-9bdd-8592ceae6129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=query), AIMessage(content=response_message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3f727-31ab-4cf5-9efb-bb73f7035a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbert_env)",
   "language": "python",
   "name": "sbert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
